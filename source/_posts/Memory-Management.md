---
title: 内存管理
tags:
  - Memory
categories: [Computer Basics,Operating System]
toc: true
date: 2022-01-21 13:20
updated: 2022-01-21 13:20
references:
  - title: 八股文（星球精华汇总）
    url: https://wx.zsxq.com/dweb2/index/topic_detail/185515824245112
  - title: 内存管理 - leetcode
    url: https://leetcode-cn.com/leetbook/read/tech-interview-cookbook/ool031/
---

内存管理是指软件运行时对计算机内存资源的分配和使用的技术。
其最主要的目的是如何高效，快速的分配，并且在适当的时候释放和回收内存资源。

虚拟内存是内存管理技术的一个极其实用的创新。

<!-- more -->

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。
此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。
在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 最佳置换 OPT

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

> 三个物理块：
>
> 7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
>
> 开始运行时，先将 7, 0, 1 三个页面装入内存。
>
> 当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 先进先出 FIFO

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。

### 最近最久未使用 LRU

> LRU, Least Recently Used

LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

> 4，7，0，7，1，0，1，2，1，2，6 <img src="https://picgo-1303870432.cos.ap-shanghai.myqcloud.com/img/202201211358376.png"  />

### 最近未使用 NRU

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。

可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 第二次机会

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

- 当页面被访问 (读或写) 时设置该页面的 R 位为 1。
- 需要替换的时候，检查最老页面的 R 位：
	- 如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉
	- 如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

<img src="https://picgo-1303870432.cos.ap-shanghai.myqcloud.com/img/202201211402284.png"  />

### 时钟 Clock

第二次机会算法需要在链表中移动页面，降低了效率。

时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

<img src="https://picgo-1303870432.cos.ap-shanghai.myqcloud.com/img/202201211400217.png"  />

## 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

如果使用分页系统的⼀维地址空间，动态增长的特点会导致覆盖问题的出现。

分段的做法是把每个表分成段，⼀个段构成⼀个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e0900bb2-220a-43b7-9aa9-1d5cd55ff56e.png" />

### 纯分段

分段和分页本质上是不同的，页面是定长的而段不是。

优点：

- 共享：有助于几个进程之间共享过程和数据。 比如共享库
- 保护：每个段都可以独立地增大或减小而不会影响其他的段

### 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。

这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

### 分段与分页的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：
	- 分页主要用于实现虚拟内存，从而获得更大的地址空间；
	- 分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

## 虚拟内存

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

属于计算机系统内存管理的⼀种技术，虚拟地址空间构成虚拟内存，它使得应用程序认为自己拥有连续的可用内存空间，但实际上是被分隔的多个物理内存页、以及部分暂时存储在磁盘上的交换分区所构成的。

虚拟内存的实现通过硬件异常、硬件地址翻译、主存、磁盘以及内核软件共同完成。

> 地址空间：是物理内存的抽象，是⼀个进程可用于寻址内存的⼀套地址集合
>
> 分页：地址空间被分割成多个块，每⼀块称作⼀页或页面 (Page)。每⼀页有连续的地址范围，这些页被映射到连续的物理内存 (页框)。
>
> 页表：把虚拟页面 (虚拟地址) 映射为页框 (物理地址)。页表给出了虚拟地址与物理地址的映射关系。从数学的角度说页表是⼀个函数，他的参数是虚拟页号，结果是物理页页框号

> 虚拟内存的思想，整体来看就是：
>
> 通过结合磁盘和内存各自的优势，利用中间层对资源进行更合理地调度，充分提高资源的利用率。并提供和谐以及统⼀的抽象。

### 优化

#### 加速

将虚拟地址直接映射到物理地址，而不必再访问页表，这种设备被称为转换检测缓冲区（TLB）、相联存储器或快表

⼯作过程：将⼀个虚拟地址放⼊MMU（内存管理单元）中进行转换时，硬件首先通过将该虚拟页号与 TLB 中所有表项同时进行匹配，

判断虚拟页面是否在其中：

1. 虚拟页号在 TLB 中。如果 MMU 检测⼀个有效的匹配并且访问操作并不违反保护位，则将页框号直接从 TLB 中取出而不必访问页表。
2. 虚拟页号不在 TLB 中。如果 MMU 检测到没有有效的匹配项就会进行正常的页表查询。接着从 TLB 中淘汰⼀个表项，然后用新的页表项替换它。

#### 加大

- 多级页表
- 倒排页表

### 重要能力

- 高速缓存
- 内存管理
- 内存保护：如果不对进程的内存访问进行限制，攻击者就能够访问和修改其他进程的私有内存，进而导致整个系统崩溃。
